{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytanie i zlepienie w jeden dataset z dodatkową kolumną do rozróżnienia zbiorów\n",
    "tt = pd.concat([\n",
    "    pd.read_hdf('./train.car_price.h5').drop(columns='price_details').assign(train=True),\n",
    "    pd.read_hdf('./test.car_price.h5').assign(train=False)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MT_LOOKUP = {\n",
    "    'styczeń': 1, 'luty': 2, 'marzec': 3, 'kwiecień': 4, 'maj': 5, 'czerwiec': 6, 'lipiec': 7, 'sierpień': 8, 'wrzesień': 9, 'październik': 10, 'listopad': 11, 'grudzień': 12,\n",
    "    'january': 1, 'february': 2, 'march': 3, 'april': 4, 'may': 5, 'june': 6, 'july': 7, 'august': 8, 'september': 9, 'october': 10, 'november': 11, 'december': 12\n",
    "}\n",
    "\n",
    "# funkcje pomocnicze\n",
    "def long_date(s):\n",
    "    if s is None:\n",
    "        return None\n",
    "    d = s.lower().split(' ')\n",
    "    if (len(d) < 3):\n",
    "        d = ['1'] + d\n",
    "    \n",
    "    return dt.date(int(d[2]), MT_LOOKUP[d[1]], int(d[0]))\n",
    "\n",
    "def as_int(m):\n",
    "    return -1 if m is None else int(m.replace(' ', '').replace('g/km', '').replace('km', '').replace('cm3', '').replace('HP', '').replace('KM', '').replace('PLN', ''))\n",
    "\n",
    "def as_float(m):\n",
    "    return -1 if m is None else float(m.replace(' ', '').replace('PLN', '').replace(',', '.'))\n",
    "\n",
    "def as_bool(m):\n",
    "    return False if m is None else True \n",
    "\n",
    "def as_obj(m):\n",
    "    return '-1' if m is None else m \n",
    "\n",
    "def param(df, c1, c2, transform=lambda x: x, data_type=np.object):\n",
    "    return df[c1].fillna(df[c2]).apply(transform).astype(data_type)\n",
    "\n",
    "\n",
    "# wstępne przygotowanie parametrów, łącząc wartości z dwóch kolumn, jeśli występuje polska i angielska wersja kolumny\n",
    "def prepare_dataset(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    t = np.bool\n",
    "    df['p_damaged'] = param(df, 'param_uszkodzony', 'param_damaged', as_bool, t)\n",
    "    df['p_pearl'] = param(df, 'param_pearl', 'param_perłowy', as_bool, t)\n",
    "    df['p_metallic'] = param(df, 'param_metalik', 'param_metallic', as_bool, t)\n",
    "    df['p_original_owner'] = param(df, 'param_original-owner', 'param_pierwszy-właściciel', as_bool, t)\n",
    "    df['p_registered_in_poland'] = param(df, 'param_registered-in-poland', 'param_zarejestrowany-w-polsce', as_bool, t)\n",
    "    df['p_no_accident'] = param(df, 'param_bezwypadkowy', 'param_no-accident', as_bool, t)\n",
    "    df['p_particle_filter'] = param(df, 'param_particle-filter', 'param_filtr-cząstek-stałych', as_bool, t)\n",
    "    df['p_leasing'] = param(df, 'param_leasing', 'param_leasing-concession', as_bool, t)\n",
    "    df['p_acrylic'] = param(df, 'param_acrylic', 'param_akryl-(niemetalizowany)', as_bool, t)\n",
    "    df['p_financing_option'] = param(df, 'param_financing-option', 'param_możliwość-finansowania', as_bool, t)\n",
    "    df['p_service-record'] = param(df, 'param_service-record', 'param_serwisowany-w-aso', as_bool, t)\n",
    "    df['p_vat_free'] = param(df, 'param_vat-free', 'param_vat-marża', as_bool, t)\n",
    "    df['p_matt'] = param(df, 'param_matowy', 'param_matowy', as_bool, t)\n",
    "    df['p_tuning'] = param(df, 'param_tuning', 'param_tuning', as_bool, t)\n",
    "    df['p_engilish_version'] = param(df, 'param_kierownica-po-prawej-(anglik)', 'param_kierownica-po-prawej-(anglik)', as_bool, t)\n",
    "    df['p_truck'] = param(df, 'param_homologacja-ciężarowa', 'param_homologacja-ciężarowa', as_bool, t)\n",
    "    df['p_vintage'] = param(df, 'param_zarejestrowany-jako-zabytek', 'param_zarejestrowany-jako-zabytek', as_bool, t)\n",
    "    df['p_vat_invoice'] = param(df, 'param_faktura-vat', 'param_faktura-vat', as_bool, t)\n",
    "    df['p_vat_discount'] = param(df, 'param_vat-discount', 'param_vat-discount', as_bool, t)\n",
    "\n",
    "    t = np.int\n",
    "    df['p_seats'] = param(df, 'param_liczba-miejsc', 'param_nr-of-seats', as_int, t)\n",
    "    df['p_doors'] = param(df, 'param_liczba-drzwi', 'param_door-count', as_int, t)\n",
    "    df['p_year'] = param(df, 'param_year', 'param_rok-produkcji', as_int, t)\n",
    "    df['p_mileage'] = param(df, 'param_mileage', 'param_przebieg', as_int, t)\n",
    "    df['p_co2_emission'] = param(df, 'param_emisja-co2', 'param_co2-emissions', as_int, t)\n",
    "    df['p_engine_capacity'] = param(df, 'param_engine-capacity', 'param_pojemność-skokowa', as_int, t)\n",
    "    df['p_engine_power'] = param(df, 'param_engine-power', 'param_moc', as_int, t)\n",
    "\n",
    "    t = np.float\n",
    "    df['p_monthly_payment'] = param(df, 'param_miesięczna-rata', 'param_monthly-payment-value', as_float, t)\n",
    "    df['p_rates_left'] = param(df, 'param_liczba-pozostałych-rat', 'param_liczba-pozostałych-rat', as_float, t)\n",
    "    df['p_redemption_value'] = param(df, 'param_wartość-wykupu', 'param_wartość-wykupu', as_float, t)\n",
    "    df['p_initial_payment'] = param(df, 'param_opłata-początkowa', 'param_opłata-początkowa', as_float, t)\n",
    "\n",
    "    t = np.object\n",
    "    df['p_model'] = param(df, 'param_model-pojazdu', 'param_model', as_obj, t)\n",
    "    df['p_make'] = param(df, 'param_marka-pojazdu', 'param_make', as_obj, t)\n",
    "    df['p_transmission'] = param(df, 'param_transmission', 'param_napęd', as_obj, t)\n",
    "    df['p_fuel_type'] = param(df, 'param_rodzaj-paliwa', 'param_fuel-type', as_obj, t)\n",
    "    df['p_body_type'] = param(df, 'param_body-type', 'param_typ', as_obj, t)\n",
    "    df['p_version'] = param(df, 'param_version', 'param_wersja', as_obj, t)\n",
    "    df['p_offered_by'] = param(df, 'param_oferta-od', 'param_oferta-od', as_obj, t)\n",
    "    df['p_vin'] = param(df, 'param_vin', 'param_vin', as_obj, t)\n",
    "    df['p_engine_code'] = param(df, 'param_engine-code', 'param_kod-silnika', as_obj, t)\n",
    "    df['p_origin_country'] = param(df, 'param_country-of-origin', 'param_kraj-pochodzenia', as_obj, t)\n",
    "    df['p_gearbox'] = param(df, 'param_gearbox', 'param_skrzynia-biegów', as_obj, t)\n",
    "    df['p_color'] = param(df, 'param_kolor', 'param_color', as_obj, t)\n",
    "    df['p_state'] = param(df, 'param_stan', 'param_stan', as_obj, t)\n",
    "    df['p_category'] = param(df, 'param_kategoria', 'param_kategoria', as_obj, t)\n",
    "    \n",
    "    df['p_first_registration'] = pd.to_datetime(param(df, 'param_first-registration', 'param_pierwsza-rejestracja', long_date, t))\n",
    "    \n",
    "    df['seller_address'] = df['seller_address'].fillna('-1')\n",
    "    df['seller_name'] = df['seller_name'].fillna('-1')\n",
    "    df['seller_type'] = df['seller_type'].fillna('-1')\n",
    "\n",
    "    return df[[c for c in df.columns if not c.startswith('param_')]]\n",
    "\n",
    "tt = prepare_dataset(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pawelg/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:2505: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['breadcrumb', 'created_at', 'price_currency', 'seller_address',\n",
      "       'seller_name', 'seller_type', 'p_model', 'p_make', 'p_transmission',\n",
      "       'p_fuel_type', 'p_body_type', 'p_version', 'p_offered_by', 'p_vin',\n",
      "       'p_engine_code', 'p_origin_country', 'p_gearbox', 'p_color', 'p_state',\n",
      "       'p_category'],\n",
      "      dtype='object')]\n",
      "\n",
      "  encoding=encoding,\n"
     ]
    }
   ],
   "source": [
    "# pomocnicze zapisywanie i odczytywanie gdybym coś później namieszał ;) \n",
    "\n",
    "# tt.to_hdf('car_price.dataset.v1.h5', 'data')\n",
    "# tt = pd.read_hdf('car_price.dataset.v1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uzupełnie brakujących danych dla: marki, modelu i kategorii\n",
    "\n",
    "def resolve_breadcrumb(df):\n",
    "    df = df.copy()  \n",
    "    def _make(r):\n",
    "        return r[1]\n",
    "\n",
    "    def _cat(r):\n",
    "        if r[0] == 'Cars':\n",
    "            return 'Osobowe'\n",
    "        return r[0]\n",
    "    \n",
    "    def _model(r):\n",
    "        mk = r[1]\n",
    "        return r[2].replace(f'{mk}-', '')\n",
    "\n",
    "    df['p_make'] = np.where(df['p_make'] == '-1', df['breadcrumb'].apply(_make), df['p_make'])\n",
    "    df['p_model'] = np.where(df['p_model'] == '-1', df['breadcrumb'].apply(_model), df['p_model'])\n",
    "    df['p_category'] = np.where(df['p_category'] == '-1', df['breadcrumb'].apply(_cat), df['p_category'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "tt = resolve_breadcrumb(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liczba dni od kiedy wisi ogłoszenie\n",
    "\n",
    "def resolve_creation_dt(df):\n",
    "    df = df.copy()  \n",
    "    MN = { 'stycznia': 1, 'lutego': 2, 'marca': 3, 'kwietnia': 4, 'maja': 5, 'czerwca': 6, 'lipca': 7, 'sierpnia': 8, 'września': 9, 'października': 10, 'listopada': 11, 'grudnia': 12}\n",
    "\n",
    "    def _created_at(r):\n",
    "        if r is None:\n",
    "            return None\n",
    "        d = r.replace(',','').split(' ')\n",
    "        return dt.date(year=int(d[3]), month=MN[d[2]], day=int(d[1])) \n",
    "    \n",
    "    df['posted_dt'] = pd.to_datetime(df['created_at'].apply(_created_at))\n",
    "    df['cf_posted_days'] = ((df['posted_dt'].max() - df['posted_dt']).dt.days + 1).fillna(-1)\n",
    "    return df\n",
    "\n",
    "tt = resolve_creation_dt(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pawelg/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:2505: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->Index(['breadcrumb', 'created_at', 'price_currency', 'seller_address',\n",
      "       'seller_name', 'seller_type', 'p_model', 'p_make', 'p_transmission',\n",
      "       'p_fuel_type', 'p_body_type', 'p_version', 'p_offered_by', 'p_vin',\n",
      "       'p_engine_code', 'p_origin_country', 'p_gearbox', 'p_color', 'p_state',\n",
      "       'p_category'],\n",
      "      dtype='object')]\n",
      "\n",
      "  encoding=encoding,\n"
     ]
    }
   ],
   "source": [
    "# tt.to_hdf('car_price.dataset.v2.h5', 'data')\n",
    "# tt = pd.read_hdf('car_price.dataset.v2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyciągnięcie przydatnych danych z wersji (początek i koniec danego modelu i czy podany rocznik mieści się w tym przedziale)\n",
    "\n",
    "def decode_version(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    p = re.compile('(^.*)\\s+\\((\\d+)\\s*-\\s*(.*)\\)')\n",
    "\n",
    "    def _resolve_ver(s):\n",
    "        if s == 'E8 i starsze (-1987)':\n",
    "            return ['E8', 1900, 1987]\n",
    "        \n",
    "        m = p.match(s)\n",
    "        if m:\n",
    "            ver, min_year, max_year = m.group(1), m.group(2), m.group(3)\n",
    "            \n",
    "            if max_year == '':\n",
    "                max_year = '2019'\n",
    "                \n",
    "            return [ver, int(min_year), int(max_year)]\n",
    "        return [s, -1, -1]\n",
    "    \n",
    "    k = df['p_version'].apply(_resolve_ver)\n",
    "    df['cf_version_name'] = k.apply(lambda x: x[0])\n",
    "    df['cf_version_min_year'] = k.apply(lambda x: x[1])\n",
    "    df['cf_version_max_year'] = k.apply(lambda x: x[2])\n",
    "    df['cf_year_in_version_range'] = (df['p_year'] != -1) & (df['cf_version_min_year'] != -1) & (df['p_year'] >= df['cf_version_min_year']) & (df['p_year'] <= df['cf_version_max_year'])\n",
    "    return df\n",
    "\n",
    "tt = decode_version(tt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policzenie liczby dni pierwszej rejestracji w stosunku do rocznika\n",
    "\n",
    "def resolve_registration_days(df):\n",
    "    df = df.copy()\n",
    "    # ręczne uzupełnienie paru ewidentnie błędnych danych\n",
    "    df.loc[37093, 'p_year'] = 1993\n",
    "    df.loc[47682, 'p_year'] = 1998\n",
    "    df.loc[123600, 'p_year'] = 2003\n",
    "    df.loc[95514, 'p_year'] = 2004\n",
    "    df.loc[10699, 'p_year'] = 1993\n",
    "    df.loc[150795, 'p_year'] = 2004\n",
    "\n",
    "    df.loc[68031, 'p_first_registration'] = '2017-01-01'\n",
    "    df.loc[103136, 'p_first_registration'] = '2014-01-19'\n",
    "    df.loc[131238, 'p_first_registration'] = '2017-06-01'\n",
    "    df.loc[53998, 'p_first_registration'] = '2006-07-31'\n",
    "    \n",
    "    def year_to_date(d):\n",
    "        return None if d is -1 else pd.Timestamp(dt.date(year=d, month=1, day=1))\n",
    "        \n",
    "    df['p_first_registration'] = pd.to_datetime(df['p_first_registration'])    \n",
    "        \n",
    "    ref = df['p_year'].apply(year_to_date)\n",
    "    df['p_first_registration'] = np.where(df['p_first_registration'] > df['posted_dt'], df['posted_dt'], df['p_first_registration'])\n",
    "    \n",
    "    df['cf_year_vs_reg_in_days'] = ((df['p_first_registration'] - df['p_year'].apply(year_to_date)).dt.days).fillna(-10000).astype(np.int16)\n",
    "    return df\n",
    "\n",
    "tt = resolve_registration_days(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyciągnięcie paru informacji z nazwy sprzedawcy i adresu\n",
    "\n",
    "def resolve_car_seller(df):\n",
    "    df = df.copy()\n",
    "    df['cf_used_car_delear'] = df['seller_name'].apply(lambda x: 'komis' in x.lower())                                      # komis\n",
    "    df['cf_used_car_seller'] = df['seller_name'].apply(lambda x: 'używ' in x.lower() or 'uzyw' in x.lower())                # używki\n",
    "    df['cf_damaged_car_seller'] = df['seller_name'].apply(lambda x: 'powypad' in x.lower())                                 # powypadkowe\n",
    "    df['cf_authorized_car_seller'] = df['seller_name'].apply(lambda x: 'autoryzow' in x.lower())                            # autoryzowany sprzedawca\n",
    "    df['cf_imported_car_seller'] = df['seller_name'].apply(lambda x: 'import' in x.lower() or 'sprowadz' in x.lower())      # importer\n",
    "    df['cf_leased_car_seller'] = df['seller_name'].apply(lambda x: 'poleas' in x.lower())                                   # poleasingowe\n",
    "    \n",
    "    df['cf_seller_address_krakow'] = df['seller_address'].apply(lambda x: 'krakow' in x.lower() or 'kraków' in x.lower())   # kraków\n",
    "    df['cf_seller_address_warszawa'] = df['seller_address'].apply(lambda x: 'warszawa' in x.lower())                        # wawa\n",
    "    df['cf_seller_address_gdansk'] = df['seller_address'].apply(lambda x: 'gdańsk' in x.lower() or 'gdansk' in x.lower())   # gdańsk\n",
    "    df['cf_seller_address_poznan'] = df['seller_address'].apply(lambda x: 'poznań' in x.lower() or 'poznan' in x.lower())   # poznań\n",
    "    df['cf_seller_address_wroclaw'] = df['seller_address'].apply(lambda x: 'wrocław' in x.lower() or 'wroclaw' in x.lower()) # wrocek\n",
    "    return df\n",
    "\n",
    "tt = resolve_car_seller(tt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skoro już wiemy coś o sprzedawcy, to można spróbować usupełnić kraj pochodzenia\n",
    "\n",
    "def adj_orig_country(df):\n",
    "    df = df.copy()\n",
    "    df.loc[df['seller_name'].str.lower().str.contains('niemiec') & (df['p_origin_country'] == '-1'), 'p_origin_country'] = 'Niemcy'\n",
    "    df.loc[df['cf_authorized_car_seller'] & ~df['cf_imported_car_seller'] & ~df['cf_used_car_seller'] & ~df['cf_damaged_car_seller'] & (df['p_origin_country'] == '-1'), 'p_origin_country'] = 'Polska'\n",
    "    return df\n",
    "\n",
    "tt = adj_orig_country(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pawelg/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:2505: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block5_values] [items->Index(['breadcrumb', 'created_at', 'price_currency', 'seller_address',\n",
      "       'seller_name', 'seller_type', 'p_model', 'p_make', 'p_transmission',\n",
      "       'p_fuel_type', 'p_body_type', 'p_version', 'p_offered_by', 'p_vin',\n",
      "       'p_engine_code', 'p_origin_country', 'p_gearbox', 'p_color', 'p_state',\n",
      "       'p_category', 'cf_version_name'],\n",
      "      dtype='object')]\n",
      "\n",
      "  encoding=encoding,\n"
     ]
    }
   ],
   "source": [
    "tt.to_hdf('car_price.dataset.v3.h5', 'data')\n",
    "tt = pd.read_hdf('car_price.dataset.v3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitralnie ustalamy czy marka jest luxusowa lub tania\n",
    "\n",
    "def make_cheap_luxury(df):\n",
    "    df = df.copy()\n",
    "    aa = df[['p_make', 'price_value']].groupby('p_make', as_index=False).agg({'price_value': ('count', 'min', 'max', 'median', 'mean', 'std')})\n",
    "    aa.columns = ['p_make', 'sample_count', 'price_min', 'price_max', 'price_median', 'price_mean', 'price_std']\n",
    "    lux = aa[aa['price_mean'] > 300_000]['p_make'].unique()\n",
    "    chp = aa[aa['price_max'] < 100_000]['p_make'].unique()\n",
    "    \n",
    "    df['cf_luxury_make'] = df['p_make'].isin(lux)\n",
    "    df['cf_cheap_make'] = df['p_make'].isin(chp)\n",
    "    return df\n",
    "\n",
    "tt = make_cheap_luxury(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitralnie ustalamy czy model jest luxusowy czy tani\n",
    "\n",
    "def model_cheap_luxury(df):\n",
    "    df = df.copy()\n",
    "    aa = df[['p_make', 'p_model', 'price_value']].groupby(['p_make', 'p_model'], as_index=False).agg({'price_value': ('count', 'min', 'max', 'median', 'mean', 'std')})\n",
    "    aa.columns = ['p_make', 'p_model', 'sample_count', 'price_min', 'price_max', 'price_median', 'price_mean', 'price_std']\n",
    "    lux = aa[aa['price_mean'] > 300_000][['p_make', 'p_model']]\n",
    "    \n",
    "    lux['cf_luxury_model'] = True\n",
    "    df = df.merge(lux, on=['p_make', 'p_model'], how='left').fillna({'cf_luxury_model': False})\n",
    "    df['cf_luxury_model'] = df['cf_luxury_model'].astype(np.bool)\n",
    "\n",
    "    chp = aa[aa['price_max'] < 50_000][['p_make', 'p_model']]\n",
    "    \n",
    "    chp['cf_cheap_model'] = True\n",
    "    df = df.merge(chp, on=['p_make', 'p_model'], how='left').fillna({'cf_cheap_model': False})\n",
    "    df['cf_cheap_model'] = df['cf_cheap_model'].astype(np.bool)\n",
    "    \n",
    "    return df\n",
    "\n",
    "tt = model_cheap_luxury(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt.to_hdf('car_price.dataset.v4.h5', 'data')\n",
    "# tt = pd.read_hdf('car_price.dataset.v4.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dziwne pojemności silnika próbuję uzupełnić na podstawie 'normalnych' wartości dla marki i modelu\n",
    "\n",
    "def adj_engine_capacity(df):\n",
    "    df = df.copy()\n",
    "    a = df.query('p_engine_capacity < 9999 and p_engine_capacity > 0')[['p_make', 'p_model', 'p_engine_capacity']].groupby(['p_make', 'p_model']).median().rename(columns={'p_engine_capacity': 'eng_cap'})\n",
    "    return df.merge(a, on=['p_make', 'p_model'], how='left') \\\n",
    "        .assign(cf_engine_capacity_adj=lambda x: np.where((x['p_engine_capacity'] >= 9999) | (x['p_engine_capacity'] <= 0), x['eng_cap'], x['p_engine_capacity']).astype(np.int16)) \\\n",
    "        .drop(columns='eng_cap')\n",
    "\n",
    "tt = adj_engine_capacity(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to samo z mocą silnika\n",
    "\n",
    "def adj_engine_power(df):\n",
    "    df = df.copy()\n",
    "    a = df.query('p_engine_power < 900 and p_engine_power > 0')[['p_make', 'p_model', 'cf_engine_capacity_adj', 'p_engine_power']] \\\n",
    "        .groupby(['p_make', 'p_model', 'cf_engine_capacity_adj']).median().rename(columns={'p_engine_power': 'eng_pow'})\n",
    "    return df.merge(a, on=['p_make', 'p_model', 'cf_engine_capacity_adj'], how='left') \\\n",
    "        .assign(cf_engine_power_adj=lambda x: np.where((x['p_engine_power'] >= 900) | (x['p_engine_power'] <= 0), x['eng_pow'], x['p_engine_power']).astype(np.int16)) \\\n",
    "        .drop(columns='eng_pow')\n",
    "\n",
    "tt = adj_engine_power(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodanie wieku i usupełnienie dziwnych przebiegów uzupełniam średnim przebiegiem (założenie 16k km rocznie)\n",
    "\n",
    "def adj_mileage(df):\n",
    "    df = df.copy()\n",
    "    df['cf_age'] = np.where(df['p_year'] > 0, 2018 - df['p_year'], -1).astype(np.int8)\n",
    "    df['cf_mileage_adj'] = np.where(((df['p_mileage'] >= 1500000) | (df['p_mileage'] < 0)) & (df['cf_age'] >=1), df['cf_age'] * 16000, df['p_mileage'])\n",
    "    return df\n",
    "\n",
    "tt = adj_mileage(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pawelg/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "# liczbę drzwi próbuję uzupełnić na podstawie typu nadwozia\n",
    "\n",
    "def adj_doors(df):\n",
    "    df = df.copy()\n",
    "    df['cf_doors_adj'] = np.where((df['p_doors'] >= 2) & (df['p_doors'] < 7), df['p_doors'], -1)\n",
    "    \n",
    "    df.loc[(df['p_body_type'] == 'Sedan') & (df['p_doors'] == '-1'), 'cf_doors_adj'] = 4\n",
    "    df.loc[(df['p_body_type'] == 'Kombi') & (df['p_doors'] == '-1'), 'cf_doors_adj'] = 5\n",
    "    df.loc[(df['p_body_type'] == 'SUV') & (df['p_doors'] == '-1'), 'cf_doors_adj'] = 5\n",
    "    df.loc[(df['p_body_type'] == 'Coupe') & (df['p_doors'] == '-1'), 'cf_doors_adj'] = 2\n",
    "    df.loc[(df['p_body_type'] == 'Minivan') & (df['p_doors'] == '-1'), 'cf_doors_adj'] = 5\n",
    "    df.loc[(df['p_body_type'] == 'Kompakt') & (df['p_doors'] == '-1'), 'cf_doors_adj'] = 5\n",
    "    df.loc[(df['p_body_type'] == 'hatchback') & (df['p_doors'] == '-1'), 'cf_doors_adj'] = 5\n",
    "    df.loc[(df['p_body_type'] == 'coupe/cabrio') & (df['p_doors'] == '-1'), 'cf_doors_adj'] = 2\n",
    "    df.loc[(df['p_body_type'] == 'Kabriolet') & (df['p_doors'] == '-1'), 'cf_doors_adj'] = 2\n",
    "    \n",
    "    \n",
    "    gr = ['p_make', 'p_model', 'p_version', 'p_body_type']\n",
    "    fb = df[(df['p_make'] != '-1') & (df['p_model'] != '-1') & (df['p_version'] != '-1') & (df['p_body_type'] != '-1') & (df['cf_doors_adj'] != -1)][gr + ['cf_doors_adj']].groupby(gr).median().rename(columns={'cf_doors_adj':'doors'})\n",
    "    df = df.merge(fb, on=gr, how='left').assign(cf_doors_adj=lambda x: np.where((x['cf_doors_adj'] == -1) & (x['doors'] > 0), x['doors'], x['cf_doors_adj'])).drop(columns='doors')\n",
    "\n",
    "    gr = ['p_make', 'p_model', 'p_version']\n",
    "    fb = df[(df['p_make'] != '-1') & (df['p_model'] != '-1') & (df['p_version'] != '-1') & (df['cf_doors_adj'] != -1)][gr + ['cf_doors_adj']].groupby(gr).median().rename(columns={'cf_doors_adj':'doors'})\n",
    "    df = df.merge(fb, on=gr, how='left').assign(cf_doors_adj=lambda x: np.where((x['cf_doors_adj'] == -1) & (x['doors'] > 0), x['doors'], x['cf_doors_adj'])).drop(columns='doors')\n",
    "\n",
    "    gr = ['p_make', 'p_model']\n",
    "    fb = df[(df['p_make'] != '-1') & (df['p_model'] != '-1') & (df['cf_doors_adj'] != -1)][gr + ['cf_doors_adj']].groupby(gr).median().rename(columns={'cf_doors_adj':'doors'})\n",
    "    df = df.merge(fb, on=gr, how='left').assign(cf_doors_adj=lambda x: np.where((x['cf_doors_adj'] == -1) & (x['doors'] > 0), x['doors'], x['cf_doors_adj'])).drop(columns='doors')\n",
    "                           \n",
    "        \n",
    "    df.loc[df['car_id'] == 59057, 'cf_doors_adj'] = 3\n",
    "    df['cf_doors_adj'] = df['cf_doors_adj'].astype(np.int8)\n",
    "    return df\n",
    "\n",
    "tt = adj_doors(tt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'faktoryzacja' cech kategorialnych\n",
    "\n",
    "def factorize_feats(df):\n",
    "    df = df.copy()\n",
    "    def _fac(c, prefix='p_'):\n",
    "        df[f'cfc_{c}'] = pd.factorize(df[f\"{prefix}{c}\"])[0]\n",
    "        return df\n",
    "    \n",
    "    df['cf_PLN'] = df['price_currency'].map({'EUR': True, 'PLN': False})\n",
    "    df = _fac('seller_type', '')\n",
    "    df = _fac('body_type')\n",
    "    df = _fac('color')\n",
    "    df = _fac('fuel_type')\n",
    "    df = _fac('gearbox')\n",
    "    df = _fac('make')\n",
    "    df = _fac('model')\n",
    "    df = _fac('offered_by')\n",
    "    df = _fac('origin_country')\n",
    "    df = _fac('state')\n",
    "    df = _fac('transmission')\n",
    "    df = _fac('version_name', 'cf_')\n",
    "    return df\n",
    "\n",
    "tt = factorize_feats(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pawelg/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:679: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# zabawa w transformacje log, pierwiastek, odwrotność\n",
    "\n",
    "def transform_feats(df):\n",
    "    df['cf_age_log'] = (np.log(df['cf_age'] + 2) - 1).astype(np.float32)\n",
    "    df['cf_mileage_sqrt'] = np.where(df['cf_mileage_adj'] > 0, np.sqrt(df['cf_mileage_adj']), -1)\n",
    "\n",
    "    df['cf_age^2'] = np.where(df['cf_age'] > 0, np.power(df['cf_age'], 2), -1).astype(np.int16)\n",
    "    df['cf_age_inverted'] = np.select([df['cf_age'] > 0, df['cf_age'] == 0], [1/df['cf_age'], 2], -1).astype(np.float32)\n",
    "    return df\n",
    "    \n",
    "tt = transform_feats(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pawelg/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:2505: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block7_values] [items->Index(['breadcrumb', 'created_at', 'price_currency', 'seller_address',\n",
      "       'seller_name', 'seller_type', 'p_model', 'p_make', 'p_transmission',\n",
      "       'p_fuel_type', 'p_body_type', 'p_version', 'p_offered_by', 'p_vin',\n",
      "       'p_engine_code', 'p_origin_country', 'p_gearbox', 'p_color', 'p_state',\n",
      "       'p_category', 'cf_version_name'],\n",
      "      dtype='object')]\n",
      "\n",
      "  encoding=encoding,\n"
     ]
    }
   ],
   "source": [
    "tt.to_hdf('car_price.dataset.v5.h5', 'data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
